{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nCreated on Mon Jun 10 15:40:22 2019\\n\\n@author: athomas7\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Mon Jun 10 15:40:22 2019\n",
    "\n",
    "@author: athomas7\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ntrain_file = \"C:/SEPP19/Eye Tracking/Single Eye/train + test.zip\"\\n\\nimport zipfile\\n\\nzf = zipfile.ZipFile(train_file)\\nzf.extractall()\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "train_file = \"C:/SEPP19/Eye Tracking/Single Eye/train + test.zip\"\n",
    "\n",
    "import zipfile\n",
    "\n",
    "zf = zipfile.ZipFile(train_file)\n",
    "zf.extractall()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "from time import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "NB_START_EPOCHS = 100\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "def load_image(file_path):\n",
    "    return cv2.imread(file_path)\n",
    "\n",
    "def extract_label(file_name):\n",
    "    return 1 if \"open\" in file_name else 0 # open eyes are 1 & closed eyes are 0\n",
    "\n",
    "train_path = \"gabor/gabor20-0/\"\n",
    "image_files = os.listdir(train_path)\n",
    "train_images = [load_image(train_path + file) for file in image_files]\n",
    "train_labels = [extract_label(file) for file in image_files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deep_model(layer, X_train, y_train, X_valid, y_valid):\n",
    "    '''\n",
    "    Function to train a multi-class model. The number of epochs and \n",
    "    batch_size are set by the constants at the top of the\n",
    "    notebook. \n",
    "    \n",
    "    Parameters:\n",
    "        model : model with the chosen architecture\n",
    "        X_train : training features\n",
    "        y_train : training target\n",
    "        X_valid : validation features\n",
    "        Y_valid : validation target\n",
    "    Output:\n",
    "        model training history\n",
    "    '''\n",
    "    model = tf.keras.Sequential(layer)\n",
    "    model.compile(optimizer='nadam'\n",
    "                  , loss='sparse_categorical_crossentropy'\n",
    "                  , metrics=['accuracy'])\n",
    "    \n",
    "    history = model.fit(X_train\n",
    "                       , y_train\n",
    "                       , epochs=NB_START_EPOCHS\n",
    "                       , batch_size=BATCH_SIZE\n",
    "                       , validation_data=(X_valid, y_valid)\n",
    "                       , verbose=0)\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_metric(model, history, metric_name):\n",
    "    '''\n",
    "    Function to evaluate a trained model on a chosen metric. \n",
    "    Training and validation metric are plotted in a\n",
    "    line chart for each epoch.\n",
    "    \n",
    "    Parameters:\n",
    "        history : model training history\n",
    "        metric_name : loss or accuracy\n",
    "    Output:\n",
    "        line chart with epochs of x-axis and metric on\n",
    "        y-axis\n",
    "    '''\n",
    "    metric = history.history[metric_name]\n",
    "    val_metric = history.history['val_' + metric_name]\n",
    "    e = range(1, NB_START_EPOCHS + 1)\n",
    "    plt.plot(e, metric, 'bo', label='Train ' + metric_name)\n",
    "    plt.plot(e, val_metric, 'b', label='Validation ' + metric_name)\n",
    "    plt.xlabel('Epoch number')\n",
    "    plt.ylabel(metric_name)\n",
    "    plt.title('Comparing training and validation ' + metric_name + ' for ' + model.name)\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimal_epoch(model_hist):\n",
    "    '''\n",
    "    Function to return the epoch number where the validation loss is\n",
    "    at its minimum\n",
    "    \n",
    "    Parameters:\n",
    "        model_hist : training history of model\n",
    "    Output:\n",
    "        epoch number with minimum validation loss\n",
    "    '''\n",
    "    min_epoch = np.argmin(model_hist.history['val_loss']) + 1\n",
    "    print(\"Minimum validation loss reached in epoch {}\".format(min_epoch))\n",
    "    return min_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this will probably not be an issue with the real deal, since all images will be the same size\n",
    "# so we can re-train with that view from the pilot's eye from the instrument...\n",
    "def preprocess_image(img, side = 96): # number of pixels on the smallest side\n",
    "    # average eye aspect ratio is 1.87 by 1 (it requires an int, so I rounded 1.87 to 2)\n",
    "    eye_aspect_ratio = 2\n",
    "    min_side = min(img.shape[0], img.shape[1])\n",
    "    img = img[:min_side, :min_side * eye_aspect_ratio]\n",
    "    img = cv2.resize(img, (side * eye_aspect_ratio, side)) # average eye aspect ratio of 1.87 by 1\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    return img / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fb8e7b5a610>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# %matplotlib inline\n",
    "preview_index = 50\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(train_images[preview_index])\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(preprocess_image(train_images[preview_index]), cmap=\"gray\")\n",
    "# some images are showing up wonky here b/c of your aspect ratio side multiplier ^^^\n",
    "# it does allow to get the entire eye within the frame though so worth it...\n",
    "# looks weird to us but the neural net will understand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(train_images)):\n",
    "    train_images[i] = preprocess_image(train_images[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "train_images = np.expand_dims(train_images, axis = -1)\n",
    "train_labels = np.array(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(144, 96, 192, 1) (144,)\n"
     ]
    }
   ],
   "source": [
    "print(train_images.shape, train_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_rest, X_valid, y_train_rest, y_valid = train_test_split(train_images, train_labels, test_size=0.1, random_state=37)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.callbacks import TensorBoard\n",
    "from tensorflow.python.keras.callbacks import EarlyStopping\n",
    "from tensorflow.python.keras.callbacks import ModelCheckpoint\n",
    "tensorboard = None\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizers = ['adam' , 'SGD' , 'RMSprop','adagrad','adadelta','adamax','nadam']\n",
    "Optimizers = ['adam' , 'adagrad' ,'nadam']\n",
    "Batch_Sizes = [16]\n",
    "Epoch_Sizes = [15]\n",
    "Activations = [tf.nn.relu , tf.nn.elu]\n",
    "Activation_name = ['relu' , 'elu' ]\n",
    "FilterSizes = [16,32,64,128,256]\n",
    "Kernel_Size = [3]\n",
    "PoolSize = [2]\n",
    "NumberOfHiddenLayer = [1,2,3]\n",
    "LayersCollection = []\n",
    "Optimizer_coll = []\n",
    "activition_coll = []\n",
    "Batch_size_coll = []\n",
    "Epoch_size_coll = []\n",
    "num_hidden_coll = []\n",
    "K_size = []\n",
    "Filetersize_coll = []\n",
    "pool_coll = []\n",
    "es = EarlyStopping(monitor='val_loss', mode = 'min' ,verbose =1 ,patience=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addFilterAndPool(Layer, Filtersize , ks , PoolSize , y , act):\n",
    "    count = y\n",
    "    while count < len(Filtersize):\n",
    "        Layer.append(tf.keras.layers.Conv2D(filters=Filtersize[count], kernel_size=(ks,ks), padding=\"same\", activation=act, input_shape=train_images.shape[1:]))\n",
    "        Layer.append(tf.keras.layers.MaxPool2D(pool_size=(PoolSize,PoolSize), strides=(PoolSize,PoolSize)))\n",
    "        count+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addHiddenLayer(Layer , num , Num_Hidden ,act):\n",
    "    temp = num*2\n",
    "    for i in range(Num_Hidden):\n",
    "        Layer.append(tf.keras.layers.Dense(units=temp , activation =act))\n",
    "        temp = temp/2\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 0\n",
    "for i in range(len(Optimizers)):\n",
    "    for j in range(len(Batch_Sizes)):\n",
    "        for k in range(len(Epoch_Sizes)):\n",
    "            for x in range(len(Activations)):\n",
    "                for Num_Hidden in NumberOfHiddenLayer:\n",
    "                    for ks in Kernel_Size:\n",
    "                        for pool in PoolSize:\n",
    "                            if pool >= ks :\n",
    "                                break\n",
    "                            layers = []\n",
    "                            addFilterAndPool(layers , FilterSizes , ks , pool , 0, Activations[x])\n",
    "                            layers.append(tf.keras.layers.Flatten())\n",
    "                            addHiddenLayer(layers , 256 , Num_Hidden ,Activations[x])\n",
    "                            layers.append(tf.keras.layers.Dense(units=2, activation=tf.nn.softmax)) # probability for each of the classes (2 as of now));\n",
    "                            LayersCollection.append(layers)\n",
    "\n",
    "                            #collection inforamtion of each layer for furture reference\n",
    "                            Optimizer_coll.append(Optimizers[i]) \n",
    "                            activition_coll.append(Activation_name[x])\n",
    "                            Batch_size_coll.append(Batch_Sizes[j])\n",
    "                            Epoch_size_coll.append(Epoch_Sizes[k])\n",
    "                            num_hidden_coll.append(Num_Hidden)\n",
    "                            K_size.append(ks)\n",
    "                            pool_coll.append(pool)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(len(Batch_Sizes)):\n",
    "#     layers = [\n",
    "#         tf.keras.layers.Conv2D(filters=16, kernel_size=(3,3), padding=\"same\", activation=tf.nn.relu, input_shape=train_images.shape[1:]),\n",
    "#         tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=(2,2)),\n",
    "#         tf.keras.layers.Conv2D(filters=32, kernel_size=(3,3), padding=\"same\", activation=tf.nn.relu, input_shape=train_images.shape[1:]),\n",
    "#         tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=(2,2)),\n",
    "#         tf.keras.layers.Conv2D(filters=64, kernel_size=(3,3), padding=\"same\", activation=tf.nn.relu, input_shape=train_images.shape[1:]),\n",
    "#         tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=(2,2)),\n",
    "#         tf.keras.layers.Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=tf.nn.relu, input_shape=train_images.shape[1:]),\n",
    "#         tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=(2,2)),\n",
    "#         tf.keras.layers.Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=tf.nn.relu, input_shape=train_images.shape[1:]),\n",
    "#         tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=(2,2)),\n",
    "#         tf.keras.layers.Flatten(),\n",
    "#         tf.keras.layers.Dense(units=512, activation=tf.nn.relu),\n",
    "#         tf.keras.layers.Dense(units=256, activation=tf.nn.relu),\n",
    "#         tf.keras.layers.Dense(units=2, activation=tf.nn.softmax) # probability for each of the classes (2 as of now)\n",
    "#     ]\n",
    "    \n",
    "#     LayersCollection.append(layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = [\n",
    "        tf.keras.layers.Conv2D(filters=16, kernel_size=(5,5), padding=\"same\", activation=tf.nn.relu, input_shape=train_images.shape[1:]),\n",
    "        tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=(2,2)),\n",
    "        tf.keras.layers.Conv2D(filters=32, kernel_size=(4,4),padding=\"same\", activation=tf.nn.relu, input_shape=train_images.shape[1:]),\n",
    "        tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=(2,2) ),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(units=64,activation=tf.nn.relu),\n",
    "        tf.keras.layers.Dense(units=2, activation=tf.nn.softmax) # probability for each of the classes (2 as of now)\n",
    "    ]\n",
    "LayersCollection.clear()\n",
    "LayersCollection.append(layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(len(LayersCollection))\n",
    "print(len(Optimizer_coll))\n",
    "print(len(activition_coll))\n",
    "print(len(Batch_size_coll))\n",
    "print(len(Epoch_size_coll))\n",
    "print(len(num_hidden_coll))\n",
    "print(len(K_size))\n",
    "print(len(pool_coll))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # https://keras.io/optimizers/ (see Adam section)\n",
    "# # https://keras.io/losses/ (see sparse_categorical_accuracy)\n",
    "# model = tf.keras.Sequential(layers)\n",
    "# model.compile(optimizer='adam',\n",
    "#               # optimizer=tf.keras.optimizers.Adam(),\n",
    "#               # loss='binary_crossentropy',\n",
    "#               # loss=tf.losses.sparse_softmax_cross_entropy(),\n",
    "#               # loss=tf.keras.backend.sparse_categorical_crossentropy(),\n",
    "#               loss='sparse_categorical_crossentropy',\n",
    "#               metrics=['accuracy'])\n",
    "#               # metrics=[tf.metrics.accuracy()])\n",
    "# \"\"\" TensorFlow 2.0.0 Beta\n",
    "# model.compile(optimizer=tf.optimizers.Adam(),\n",
    "#               loss=tf.losses.SparseCategoricalCrossentropy(),\n",
    "#               metrics=[tf.metrics.SparseCategoricalAccuracy()])\n",
    "# \"\"\"\n",
    "# tensorboard = TensorBoard(log_dir=\"logs/{}\".format(time()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00023: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fb8cfb8e450>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = tf.keras.Sequential(LayersCollection[0])\n",
    "model.compile(optimizer='nadam'\n",
    "                , loss='sparse_categorical_crossentropy'\n",
    "                , metrics=['accuracy'])\n",
    "    \n",
    "model.fit(X_train_rest\n",
    "                    , y_train_rest\n",
    "                    , epochs=30\n",
    "                    , batch_size=BATCH_SIZE\n",
    "                    , validation_data=(X_valid, y_valid)\n",
    "                    , verbose=0\n",
    "                    , callbacks=[es])\n",
    "#base_min = optimal_epoch(history)\n",
    "#eval_metric(model, history, 'loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "models = []\n",
    "\n",
    "for layer in LayersCollection:\n",
    "    # https://keras.io/optimizers/ (see Adam section)\n",
    "    # https://keras.io/losses/ (see sparse_categorical_accuracy)\n",
    "    model = tf.keras.Sequential(layer)\n",
    "    model.compile(optimizer='nadam',\n",
    "                    # optimizer=tf.keras.optimizers.Adam(),\n",
    "                    # loss='binary_crossentropy',\n",
    "                    # loss=tf.losses.sparse_softmax_cross_entropy(),\n",
    "                    # loss=tf.keras.backend.sparse_categorical_crossentropy(),\n",
    "                    loss='sparse_categorical_crossentropy',\n",
    "                    metrics=['accuracy'])\n",
    "                    # metrics=[tf.metrics.accuracy()])\n",
    "    \"\"\" TensorFlow 2.0.0 Beta\n",
    "    model.compile(optimizer=tf.optimizers.Adam(),\n",
    "                    loss=tf.losses.SparseCategoricalCrossentropy(),\n",
    "                    metrics=[tf.metrics.SparseCategoricalAccuracy()])\n",
    "    \"\"\"\n",
    "    models.append(model)\n",
    "#     print(Optimizer_coll[i])\n",
    "#     print(activition_coll[i])\n",
    "#     print(Batch_size_coll[i])\n",
    "#     print(Epoch_size_coll[i])\n",
    "#     print(num_hidden_coll[i])\n",
    "#     print(pool_coll[i])\n",
    "\n",
    "#     name = \"logs/OpenClosedEye_\" + Optimizer_coll[i] + activition_coll[i]+ str(i);  \n",
    "#     tensorboard = TensorBoard(log_dir=name)\n",
    "#     model.fit(train_images, train_labels, epochs=Epoch_size_coll[i], batch_size=Batch_size_coll[i] , callbacks=[tensorboard])\n",
    "#    model.save(\"model\"+str(i)+\".h5\")\n",
    "#     i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 144 samples\n",
      "Epoch 1/25\n",
      "144/144 [==============================] - 2s 16ms/sample - loss: 0.3173 - accuracy: 0.8681\n",
      "Epoch 2/25\n",
      "144/144 [==============================] - 2s 12ms/sample - loss: 0.3563 - accuracy: 0.8889\n",
      "Epoch 3/25\n",
      "144/144 [==============================] - 2s 11ms/sample - loss: 0.1860 - accuracy: 0.9306\n",
      "Epoch 4/25\n",
      "144/144 [==============================] - 2s 12ms/sample - loss: 0.1306 - accuracy: 0.9375\n",
      "Epoch 5/25\n",
      "144/144 [==============================] - 2s 11ms/sample - loss: 0.0900 - accuracy: 0.9722\n",
      "Epoch 6/25\n",
      "144/144 [==============================] - 2s 12ms/sample - loss: 0.0588 - accuracy: 0.9861\n",
      "Epoch 7/25\n",
      "144/144 [==============================] - 2s 16ms/sample - loss: 0.0266 - accuracy: 0.9931\n",
      "Epoch 8/25\n",
      "144/144 [==============================] - 2s 13ms/sample - loss: 0.0109 - accuracy: 1.0000\n",
      "Epoch 9/25\n",
      "144/144 [==============================] - 2s 13ms/sample - loss: 0.0046 - accuracy: 1.0000\n",
      "Epoch 10/25\n",
      "144/144 [==============================] - 2s 12ms/sample - loss: 0.0028 - accuracy: 1.0000\n",
      "Epoch 11/25\n",
      "144/144 [==============================] - 2s 13ms/sample - loss: 0.0018 - accuracy: 1.0000\n",
      "Epoch 12/25\n",
      "144/144 [==============================] - 2s 14ms/sample - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 13/25\n",
      "144/144 [==============================] - 2s 14ms/sample - loss: 9.7972e-04 - accuracy: 1.0000\n",
      "Epoch 14/25\n",
      "144/144 [==============================] - 2s 15ms/sample - loss: 8.3516e-04 - accuracy: 1.0000\n",
      "Epoch 15/25\n",
      "144/144 [==============================] - 2s 15ms/sample - loss: 6.6973e-04 - accuracy: 1.0000\n",
      "Epoch 16/25\n",
      "144/144 [==============================] - 2s 15ms/sample - loss: 5.7655e-04 - accuracy: 1.0000\n",
      "Epoch 17/25\n",
      "144/144 [==============================] - 2s 16ms/sample - loss: 4.9645e-04 - accuracy: 1.0000\n",
      "Epoch 18/25\n",
      "144/144 [==============================] - 3s 18ms/sample - loss: 4.3922e-04 - accuracy: 1.0000\n",
      "Epoch 19/25\n",
      "144/144 [==============================] - 2s 16ms/sample - loss: 3.7950e-04 - accuracy: 1.0000\n",
      "Epoch 20/25\n",
      "144/144 [==============================] - 2s 17ms/sample - loss: 3.3267e-04 - accuracy: 1.0000\n",
      "Epoch 21/25\n",
      "144/144 [==============================] - 2s 15ms/sample - loss: 2.9125e-04 - accuracy: 1.0000\n",
      "Epoch 22/25\n",
      "144/144 [==============================] - 2s 15ms/sample - loss: 2.5851e-04 - accuracy: 1.0000\n",
      "Epoch 23/25\n",
      "144/144 [==============================] - 2s 14ms/sample - loss: 2.3778e-04 - accuracy: 1.0000\n",
      "Epoch 24/25\n",
      "144/144 [==============================] - 2s 15ms/sample - loss: 2.1811e-04 - accuracy: 1.0000\n",
      "Epoch 25/25\n",
      "144/144 [==============================] - 2s 15ms/sample - loss: 1.9215e-04 - accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# Training the model\n",
    "import time\n",
    "i = 0\n",
    "for model in models:\n",
    "    name = \"logs/OpenClosedEye_with_Batchsize\" + str(i)\n",
    "    tensorboard = TensorBoard(log_dir=name)\n",
    "    model.fit(train_images, train_labels, epochs=25, batch_size=Batch_Sizes[i%len(Batch_Sizes)] , callbacks=[tensorboard])\n",
    "    i = i+1\n",
    "#     model.save_weights(\"model\"+str(i)+\"tf\")\n",
    "#     model.save(\"model\"+str(i)+\".h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-5335fc81ff67f6aa\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-5335fc81ff67f6aa\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          url.port = 6006;\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Unable to open file (unable to open file: name = 'model0.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-93-09f9ceecf261>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# eval_images = [preprocess_image(load_image(file)) for file in uploads].keys()]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0meval_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLayersCollection\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0meval_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"model0.h5\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0meval_predictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meval_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/spyder/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mload_weights\u001b[0;34m(self, filepath, by_name, skip_mismatch)\u001b[0m\n\u001b[1;32m    232\u001b[0m         raise ValueError('Load weights is not yet supported with TPUStrategy '\n\u001b[1;32m    233\u001b[0m                          'with steps_per_run greater than 1.')\n\u001b[0;32m--> 234\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mby_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskip_mismatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mtrackable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_automatic_dependency_tracking\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/spyder/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/network.py\u001b[0m in \u001b[0;36mload_weights\u001b[0;34m(self, filepath, by_name, skip_mismatch)\u001b[0m\n\u001b[1;32m   1213\u001b[0m           'first, then load the weights.')\n\u001b[1;32m   1214\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_assert_weights_created\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1215\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1216\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'layer_names'\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattrs\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m'model_weights'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1217\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model_weights'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/spyder/lib/python3.7/site-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode, driver, libver, userblock_size, swmr, **kwds)\u001b[0m\n\u001b[1;32m    310\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mphil\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m                 \u001b[0mfapl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_fapl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdriver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlibver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 312\u001b[0;31m                 \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_fid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muserblock_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mswmr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mswmr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/spyder/lib/python3.7/site-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36mmake_fid\u001b[0;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mswmr\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m             \u001b[0mflags\u001b[0m \u001b[0;34m|=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_SWMR_READ\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'r+'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_RDWR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/h5f.pyx\u001b[0m in \u001b[0;36mh5py.h5f.open\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: Unable to open file (unable to open file: name = 'model0.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import cv2\n",
    "\n",
    "test_file = \"closed_eye_75.jpg\"\n",
    "uploads = cv2.imread(\"test/\" + test_file)\n",
    "\n",
    "\"\"\" For Multiple Images...\n",
    "import glob\n",
    "import cv2\n",
    "images = [cv2.imread(file) for file in glob.glob(\"path/to/files/*.png\")]\n",
    "\"\"\"\n",
    "\n",
    "eval_images = [preprocess_image(uploads)] # must be an array because of the for-loop below\n",
    "# eval_images = [preprocess_image(load_image(file)) for file in uploads].keys()]\n",
    "eval_model = tf.keras.Sequential(LayersCollection[0])\n",
    "eval_model.load_weights(\"model0.h5\")\n",
    "eval_predictions = eval_model.predict(np.expand_dims(eval_images, axis = -1))\n",
    "\n",
    "cols = 4\n",
    "rows = np.ceil(len(eval_images)/cols)\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(cols*4, rows*4)\n",
    "for i in range(len(eval_images)):\n",
    "    plt.subplot(rows, cols, i+1)\n",
    "    plt.imshow(eval_images[i], cmap=\"gray\")\n",
    "    plt.title(\"Open\" if np.argmax(eval_predictions[i])==1 else \"Closed\")\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'models' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-faa34c4b5a7a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     28\u001b[0m                                 \u001b[0mtemp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mpreprocess_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m                                 \u001b[0mbegin_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m                                 \u001b[0meval_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m                                 \u001b[0meval_predictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m                                 \u001b[0mend_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'models' is not defined"
     ]
    }
   ],
   "source": [
    "test_path = \"gabor/gabor20-0_test/\"\n",
    "test_files = os.listdir(test_path)\n",
    "test_images = [load_image(test_path + file) for file in test_files]\n",
    "test_labels = [extract_label(file) for file in test_files]\n",
    "\n",
    "# eval_model = tf.keras.Sequential(layers)\n",
    "# eval_model.load_weights(\"model.h5\")\n",
    "\n",
    "import time\n",
    "\n",
    "above = []\n",
    "lantancys = []\n",
    "accur = []\n",
    "\n",
    "j = 0\n",
    "\n",
    "for f in range(len(Optimizers)):\n",
    "    for a in range(len(Batch_Sizes)):\n",
    "        for k in range(len(Epoch_Sizes)):\n",
    "            for x in range(len(Activations)):\n",
    "                for Num_Hidden in NumberOfHiddenLayer:\n",
    "                    for ks in Kernel_Size:\n",
    "                        for pool in PoolSize:\n",
    "                            right = 0\n",
    "                            total = 0\n",
    "                            for i in range(len(test_images)):\n",
    "                                temp = test_images[i]\n",
    "                                temp = [preprocess_image(temp)]\n",
    "                                begin_time = int(round(time.time() * 1000))\n",
    "                                eval_model = models[x]\n",
    "                                eval_predictions = eval_model.predict(np.expand_dims(temp , axis= -1))\n",
    "                                end_time = int(round(time.time() * 1000))\n",
    "                                if (test_labels[i] == 1 and np.argmax(eval_predictions[0])==1) or (test_labels[i] == 0 and np.argmax(eval_predictions[0])!=1):\n",
    "                                    right+=1\n",
    "                                total+= end_time-begin_time\n",
    "\n",
    "                            print(\"accuracy for \",j,\" is :\",right/64*100 , \"%\")\n",
    "                            print(\"time spent for \" ,j, \" is : \" , total , \"ms\")\n",
    "                            j = j +1\n",
    "                            above.append(x)\n",
    "                            lantancys.append(total)\n",
    "                            accur.append(right/64*100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizer_coll = []\n",
    "# activition_coll = []\n",
    "# Batch_size_coll = []\n",
    "# Epoch_size_coll = []\n",
    "# num_hidden_coll = []\n",
    "# Filetersize_coll = []\n",
    "# pool_coll = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 6, 8, 9, 15, 19, 20, 24, 26, 27, 30, 31, 33, 34, 37, 39, 40, 41, 42, 43, 45, 48, 49]\n"
     ]
    }
   ],
   "source": [
    "print(above)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optmizer: adam ,Activition function: relu ,Num of hiddenlayer: 2 ,Kernel size:  3  with lantancys : 28.609375 ms   ,accurancy:  98.4375 %\n",
      "optmizer: adam ,Activition function: relu ,Num of hiddenlayer: 3 ,Kernel size:  3  with lantancys : 28.453125 ms   ,accurancy:  98.4375 %\n",
      "optmizer: adam ,Activition function: relu ,Num of hiddenlayer: 3 ,Kernel size:  5  with lantancys : 31.6875 ms   ,accurancy:  100.0 %\n",
      "optmizer: adam ,Activition function: elu ,Num of hiddenlayer: 1 ,Kernel size:  3  with lantancys : 28.53125 ms   ,accurancy:  98.4375 %\n",
      "optmizer: adam ,Activition function: elu ,Num of hiddenlayer: 3 ,Kernel size:  3  with lantancys : 29.03125 ms   ,accurancy:  100.0 %\n",
      "optmizer: adagrad ,Activition function: relu ,Num of hiddenlayer: 1 ,Kernel size:  4  with lantancys : 29.515625 ms   ,accurancy:  98.4375 %\n",
      "optmizer: adagrad ,Activition function: relu ,Num of hiddenlayer: 1 ,Kernel size:  5  with lantancys : 31.78125 ms   ,accurancy:  98.4375 %\n",
      "optmizer: adagrad ,Activition function: relu ,Num of hiddenlayer: 3 ,Kernel size:  3  with lantancys : 28.78125 ms   ,accurancy:  98.4375 %\n",
      "optmizer: adagrad ,Activition function: relu ,Num of hiddenlayer: 3 ,Kernel size:  5  with lantancys : 37.328125 ms   ,accurancy:  98.4375 %\n",
      "optmizer: adagrad ,Activition function: elu ,Num of hiddenlayer: 1 ,Kernel size:  3  with lantancys : 28.96875 ms   ,accurancy:  100.0 %\n",
      "optmizer: adagrad ,Activition function: elu ,Num of hiddenlayer: 2 ,Kernel size:  3  with lantancys : 28.71875 ms   ,accurancy:  100.0 %\n",
      "optmizer: adagrad ,Activition function: elu ,Num of hiddenlayer: 2 ,Kernel size:  4  with lantancys : 30.328125 ms   ,accurancy:  98.4375 %\n",
      "optmizer: adagrad ,Activition function: elu ,Num of hiddenlayer: 3 ,Kernel size:  3  with lantancys : 28.5625 ms   ,accurancy:  100.0 %\n",
      "optmizer: adagrad ,Activition function: elu ,Num of hiddenlayer: 3 ,Kernel size:  4  with lantancys : 29.90625 ms   ,accurancy:  98.4375 %\n",
      "optmizer: nadam ,Activition function: relu ,Num of hiddenlayer: 1 ,Kernel size:  4  with lantancys : 29.234375 ms   ,accurancy:  98.4375 %\n",
      "optmizer: nadam ,Activition function: relu ,Num of hiddenlayer: 2 ,Kernel size:  3  with lantancys : 28.0625 ms   ,accurancy:  100.0 %\n",
      "optmizer: nadam ,Activition function: relu ,Num of hiddenlayer: 2 ,Kernel size:  4  with lantancys : 29.796875 ms   ,accurancy:  100.0 %\n",
      "optmizer: nadam ,Activition function: relu ,Num of hiddenlayer: 2 ,Kernel size:  5  with lantancys : 31.421875 ms   ,accurancy:  98.4375 %\n",
      "optmizer: nadam ,Activition function: relu ,Num of hiddenlayer: 3 ,Kernel size:  3  with lantancys : 28.203125 ms   ,accurancy:  98.4375 %\n",
      "optmizer: nadam ,Activition function: relu ,Num of hiddenlayer: 3 ,Kernel size:  4  with lantancys : 30.109375 ms   ,accurancy:  98.4375 %\n",
      "optmizer: nadam ,Activition function: elu ,Num of hiddenlayer: 1 ,Kernel size:  3  with lantancys : 28.515625 ms   ,accurancy:  98.4375 %\n",
      "optmizer: nadam ,Activition function: elu ,Num of hiddenlayer: 2 ,Kernel size:  3  with lantancys : 29.28125 ms   ,accurancy:  98.4375 %\n",
      "optmizer: nadam ,Activition function: elu ,Num of hiddenlayer: 2 ,Kernel size:  4  with lantancys : 29.734375 ms   ,accurancy:  98.4375 %\n"
     ]
    }
   ],
   "source": [
    "for i , j , k in zip(above, lantancys , accur):\n",
    "    print(\"optmizer:\" , Optimizer_coll[i] , \",Activition function:\", activition_coll[i] , \",Num of hiddenlayer:\" , num_hidden_coll[i] ,\",Kernel size: \", K_size[i] , \" with lantancys :\" , j/64 , \"ms\", \"  ,accurancy: \" , k , \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "img_arr = np.array(preprocess_image(uploads))\n",
    "print(len(img_arr.flatten()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
