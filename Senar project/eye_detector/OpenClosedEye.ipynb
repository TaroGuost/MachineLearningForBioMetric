{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nCreated on Mon Jun 10 15:40:22 2019\\n\\n@author: athomas7\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Mon Jun 10 15:40:22 2019\n",
    "\n",
    "@author: athomas7\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ntrain_file = \"C:/SEPP19/Eye Tracking/Single Eye/train + test.zip\"\\n\\nimport zipfile\\n\\nzf = zipfile.ZipFile(train_file)\\nzf.extractall()\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "train_file = \"C:/SEPP19/Eye Tracking/Single Eye/train + test.zip\"\n",
    "\n",
    "import zipfile\n",
    "\n",
    "zf = zipfile.ZipFile(train_file)\n",
    "zf.extractall()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "from time import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "NB_START_EPOCHS = 100\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "def load_image(file_path):\n",
    "    return cv2.imread(file_path)\n",
    "\n",
    "def extract_label(file_name):\n",
    "    return 1 if \"open\" in file_name else 0 # open eyes are 1 & closed eyes are 0\n",
    "\n",
    "train_path = \"ftrain2/\"\n",
    "image_files = os.listdir(train_path)\n",
    "train_images = [load_image(train_path + file) for file in image_files]\n",
    "train_labels = [extract_label(file) for file in image_files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deep_model(layer, X_train, y_train, X_valid, y_valid):\n",
    "    '''\n",
    "    Function to train a multi-class model. The number of epochs and \n",
    "    batch_size are set by the constants at the top of the\n",
    "    notebook. \n",
    "    \n",
    "    Parameters:\n",
    "        model : model with the chosen architecture\n",
    "        X_train : training features\n",
    "        y_train : training target\n",
    "        X_valid : validation features\n",
    "        Y_valid : validation target\n",
    "    Output:\n",
    "        model training history\n",
    "    '''\n",
    "    model = tf.keras.Sequential(layer)\n",
    "    model.compile(optimizer='nadam'\n",
    "                  , loss='sparse_categorical_crossentropy'\n",
    "                  , metrics=['accuracy'])\n",
    "    \n",
    "    history = model.fit(X_train\n",
    "                       , y_train\n",
    "                       , epochs=NB_START_EPOCHS\n",
    "                       , batch_size=BATCH_SIZE\n",
    "                       , validation_data=(X_valid, y_valid)\n",
    "                       , verbose=0)\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_metric(model, history, metric_name):\n",
    "    '''\n",
    "    Function to evaluate a trained model on a chosen metric. \n",
    "    Training and validation metric are plotted in a\n",
    "    line chart for each epoch.\n",
    "    \n",
    "    Parameters:\n",
    "        history : model training history\n",
    "        metric_name : loss or accuracy\n",
    "    Output:\n",
    "        line chart with epochs of x-axis and metric on\n",
    "        y-axis\n",
    "    '''\n",
    "    metric = history.history[metric_name]\n",
    "    val_metric = history.history['val_' + metric_name]\n",
    "    e = range(1, NB_START_EPOCHS + 1)\n",
    "    plt.plot(e, metric, 'bo', label='Train ' + metric_name)\n",
    "    plt.plot(e, val_metric, 'b', label='Validation ' + metric_name)\n",
    "    plt.xlabel('Epoch number')\n",
    "    plt.ylabel(metric_name)\n",
    "    plt.title('Comparing training and validation ' + metric_name + ' for ' + model.name)\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimal_epoch(model_hist):\n",
    "    '''\n",
    "    Function to return the epoch number where the validation loss is\n",
    "    at its minimum\n",
    "    \n",
    "    Parameters:\n",
    "        model_hist : training history of model\n",
    "    Output:\n",
    "        epoch number with minimum validation loss\n",
    "    '''\n",
    "    min_epoch = np.argmin(model_hist.history['val_loss']) + 1\n",
    "    print(\"Minimum validation loss reached in epoch {}\".format(min_epoch))\n",
    "    return min_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this will probably not be an issue with the real deal, since all images will be the same size\n",
    "# so we can re-train with that view from the pilot's eye from the instrument...\n",
    "def preprocess_image(img, side = 96): # number of pixels on the smallest side\n",
    "    # average eye aspect ratio is 1.87 by 1 (it requires an int, so I rounded 1.87 to 2)\n",
    "    eye_aspect_ratio = 2\n",
    "    min_side = min(img.shape[0], img.shape[1])\n",
    "    img = img[:min_side, :min_side * eye_aspect_ratio]\n",
    "    img = cv2.resize(img, (side * eye_aspect_ratio, side)) # average eye aspect ratio of 1.87 by 1\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    return img / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f5188059850>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# %matplotlib inline\n",
    "preview_index = 50\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(train_images[preview_index])\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(preprocess_image(train_images[preview_index]), cmap=\"gray\")\n",
    "# some images are showing up wonky here b/c of your aspect ratio side multiplier ^^^\n",
    "# it does allow to get the entire eye within the frame though so worth it...\n",
    "# looks weird to us but the neural net will understand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(train_images)):\n",
    "    train_images[i] = preprocess_image(train_images[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "train_images = np.expand_dims(train_images, axis = -1)\n",
    "train_labels = np.array(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(144, 96, 192, 1) (144,)\n"
     ]
    }
   ],
   "source": [
    "print(train_images.shape, train_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_rest, X_valid, y_train_rest, y_valid = train_test_split(train_images, train_labels, test_size=0.2, random_state=37)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.callbacks import TensorBoard\n",
    "from tensorflow.python.keras.callbacks import EarlyStopping\n",
    "from tensorflow.python.keras.callbacks import ModelCheckpoint\n",
    "tensorboard = None\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizers = ['adam' , 'SGD' , 'RMSprop','adagrad','adadelta','adamax','nadam']\n",
    "Optimizers = ['adam' , 'adagrad' ,'nadam']\n",
    "Learning_Rate = [0.001 , 0.005 , 0.01 , 0.05 , 0.1 , 0.5 , 0.9]\n",
    "Batch_Sizes = [16]\n",
    "Epoch_Sizes = [15]\n",
    "Activations = [tf.nn.relu , tf.nn.elu]\n",
    "Activation_name = ['relu' , 'elu' ]\n",
    "FilterSizes = [16,32,64,128,256]\n",
    "Kernel_Size = [3]\n",
    "PoolSize = [2]\n",
    "NumberOfHiddenLayer = [1,2,3]\n",
    "LayersCollection = []\n",
    "Optimizer_coll = []\n",
    "activition_coll = []\n",
    "Batch_size_coll = []\n",
    "Epoch_size_coll = []\n",
    "num_hidden_coll = []\n",
    "K_size = []\n",
    "Filetersize_coll = []\n",
    "pool_coll = []\n",
    "es = EarlyStopping(monitor='val_loss', mode = 'min' ,verbose =1 ,patience=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addFilterAndPool(Layer, Filtersize , ks , PoolSize , y , act):\n",
    "    count = y\n",
    "    while count < len(Filtersize):\n",
    "        Layer.append(tf.keras.layers.Conv2D(filters=Filtersize[count], kernel_size=(ks,ks), padding=\"same\", activation=act, input_shape=train_images.shape[1:]))\n",
    "        Layer.append(tf.keras.layers.MaxPool2D(pool_size=(PoolSize,PoolSize), strides=(PoolSize,PoolSize)))\n",
    "        count+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addHiddenLayer(Layer , num , Num_Hidden ,act):\n",
    "    temp = num*2\n",
    "    for i in range(Num_Hidden):\n",
    "        Layer.append(tf.keras.layers.Dense(units=temp , activation =act))\n",
    "        temp = temp/2\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 0\n",
    "for i in range(len(Optimizers)):\n",
    "    for j in range(len(Batch_Sizes)):\n",
    "        for k in range(len(Epoch_Sizes)):\n",
    "            for x in range(len(Activations)):\n",
    "                for Num_Hidden in NumberOfHiddenLayer:\n",
    "                    for ks in Kernel_Size:\n",
    "                        for pool in PoolSize:\n",
    "                            if pool >= ks :\n",
    "                                break\n",
    "                            layers = []\n",
    "                            addFilterAndPool(layers , FilterSizes , ks , pool , 0, Activations[x])\n",
    "                            layers.append(tf.keras.layers.Flatten())\n",
    "                            addHiddenLayer(layers , 256 , Num_Hidden ,Activations[x])\n",
    "                            layers.append(tf.keras.layers.Dense(units=2, activation=tf.nn.softmax)) # probability for each of the classes (2 as of now));\n",
    "                            LayersCollection.append(layers)\n",
    "\n",
    "                            #collection inforamtion of each layer for furture reference\n",
    "                            Optimizer_coll.append(Optimizers[i]) \n",
    "                            activition_coll.append(Activation_name[x])\n",
    "                            Batch_size_coll.append(Batch_Sizes[j])\n",
    "                            Epoch_size_coll.append(Epoch_Sizes[k])\n",
    "                            num_hidden_coll.append(Num_Hidden)\n",
    "                            K_size.append(ks)\n",
    "                            pool_coll.append(pool)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(Learning_Rate)):\n",
    "    layers = [\n",
    "        tf.keras.layers.Conv2D(filters=16, kernel_size=(6,6), padding=\"same\", activation=tf.nn.relu, input_shape=train_images.shape[1:]),\n",
    "        tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=(2,2)),\n",
    "        tf.keras.layers.Conv2D(filters=32, kernel_size=(5,5), padding=\"same\", activation=tf.nn.relu, input_shape=train_images.shape[1:]),\n",
    "        tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=(2,2)),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(units=64,activation=tf.nn.relu),\n",
    "        tf.keras.layers.Dense(units=2, activation=tf.nn.softmax) # probability for each of the classes (2 as of now)\n",
    "    ]\n",
    "    \n",
    "    LayersCollection.append(layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = [\n",
    "        tf.keras.layers.Conv2D(filters=16, kernel_size=(6,6), padding=\"same\", activation=tf.nn.relu, input_shape=train_images.shape[1:]),\n",
    "        tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=(2,2)),\n",
    "        tf.keras.layers.Conv2D(filters=32, kernel_size=(5,5), padding=\"same\", activation=tf.nn.relu, input_shape=train_images.shape[1:]),\n",
    "        tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=(2,2)),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(units=64,activation=tf.nn.relu),\n",
    "        tf.keras.layers.Dense(units=2, activation=tf.nn.softmax) # probability for each of the classes (2 as of now)\n",
    "    ]\n",
    "LayersCollection.clear()\n",
    "LayersCollection.append(layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(len(LayersCollection))\n",
    "print(len(Optimizer_coll))\n",
    "print(len(activition_coll))\n",
    "print(len(Batch_size_coll))\n",
    "print(len(Epoch_size_coll))\n",
    "print(len(num_hidden_coll))\n",
    "print(len(K_size))\n",
    "print(len(pool_coll))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # https://keras.io/optimizers/ (see Adam section)\n",
    "# # https://keras.io/losses/ (see sparse_categorical_accuracy)\n",
    "# model = tf.keras.Sequential(layers)\n",
    "# model.compile(optimizer='adam',\n",
    "#               # optimizer=tf.keras.optimizers.Adam(),\n",
    "#               # loss='binary_crossentropy',\n",
    "#               # loss=tf.losses.sparse_softmax_cross_entropy(),\n",
    "#               # loss=tf.keras.backend.sparse_categorical_crossentropy(),\n",
    "#               loss='sparse_categorical_crossentropy',\n",
    "#               metrics=['accuracy'])\n",
    "#               # metrics=[tf.metrics.accuracy()])\n",
    "# \"\"\" TensorFlow 2.0.0 Beta\n",
    "# model.compile(optimizer=tf.optimizers.Adam(),\n",
    "#               loss=tf.losses.SparseCategoricalCrossentropy(),\n",
    "#               metrics=[tf.metrics.SparseCategoricalAccuracy()])\n",
    "# \"\"\"\n",
    "# tensorboard = TensorBoard(log_dir=\"logs/{}\".format(time()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum validation loss reached in epoch 36\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = tf.keras.Sequential(LayersCollection[0])\n",
    "model.compile(optimizer='nadam'\n",
    "                , loss='sparse_categorical_crossentropy'\n",
    "                , metrics=['accuracy'])\n",
    "    \n",
    "history = model.fit(X_train_rest\n",
    "                    , y_train_rest\n",
    "                    , epochs=100\n",
    "                    , batch_size=BATCH_SIZE\n",
    "                    , validation_data=(X_valid, y_valid)\n",
    "                    , verbose=0\n",
    "#                    , callbacks=[es]\n",
    "         )\n",
    "base_min = optimal_epoch(history)\n",
    "eval_metric(model, history, 'loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "models = []\n",
    "\n",
    "for layer in LayersCollection:\n",
    "    # https://keras.io/optimizers/ (see Adam section)\n",
    "    # https://keras.io/losses/ (see sparse_categorical_accuracy)\n",
    "    model = tf.keras.Sequential(layer)\n",
    "    model.compile(optimizer='nadam',\n",
    "                    # optimizer=tf.keras.optimizers.Adam(),\n",
    "                    # loss='binary_crossentropy',\n",
    "                    # loss=tf.losses.sparse_softmax_cross_entropy(),\n",
    "                    # loss=tf.keras.backend.sparse_categorical_crossentropy(),\n",
    "                    loss='sparse_categorical_crossentropy',\n",
    "                    metrics=['accuracy'])\n",
    "                    # metrics=[tf.metrics.accuracy()])\n",
    "    \"\"\" TensorFlow 2.0.0 Beta\n",
    "    model.compile(optimizer=tf.optimizers.Adam(),\n",
    "                    loss=tf.losses.SparseCategoricalCrossentropy(),\n",
    "                    metrics=[tf.metrics.SparseCategoricalAccuracy()])\n",
    "    \"\"\"\n",
    "    models.append(model)\n",
    "#     print(Optimizer_coll[i])\n",
    "#     print(activition_coll[i])\n",
    "#     print(Batch_size_coll[i])\n",
    "#     print(Epoch_size_coll[i])\n",
    "#     print(num_hidden_coll[i])\n",
    "#     print(pool_coll[i])\n",
    "\n",
    "#     name = \"logs/OpenClosedEye_\" + Optimizer_coll[i] + activition_coll[i]+ str(i);  \n",
    "#     tensorboard = TensorBoard(log_dir=name)\n",
    "#     model.fit(train_images, train_labels, epochs=Epoch_size_coll[i], batch_size=Batch_size_coll[i] , callbacks=[tensorboard])\n",
    "#    model.save(\"model\"+str(i)+\".h5\")\n",
    "#     i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model.optimizer.lr = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 144 samples, validate on 29 samples\n",
      "Epoch 1/30\n",
      "144/144 [==============================] - 3s 21ms/sample - loss: 0.9163 - accuracy: 0.5764 - val_loss: 0.5955 - val_accuracy: 0.5517\n",
      "Epoch 2/30\n",
      "144/144 [==============================] - 2s 14ms/sample - loss: 0.4575 - accuracy: 0.8125 - val_loss: 0.2850 - val_accuracy: 0.8966\n",
      "Epoch 3/30\n",
      "144/144 [==============================] - 2s 14ms/sample - loss: 0.3719 - accuracy: 0.8542 - val_loss: 0.1392 - val_accuracy: 1.0000\n",
      "Epoch 4/30\n",
      "144/144 [==============================] - 2s 16ms/sample - loss: 0.2424 - accuracy: 0.9097 - val_loss: 0.0993 - val_accuracy: 1.0000\n",
      "Epoch 5/30\n",
      "144/144 [==============================] - 2s 14ms/sample - loss: 0.1551 - accuracy: 0.9583 - val_loss: 0.0627 - val_accuracy: 1.0000\n",
      "Epoch 6/30\n",
      "144/144 [==============================] - 2s 15ms/sample - loss: 0.1053 - accuracy: 0.9722 - val_loss: 0.0301 - val_accuracy: 1.0000\n",
      "Epoch 7/30\n",
      "144/144 [==============================] - 2s 14ms/sample - loss: 0.0733 - accuracy: 0.9792 - val_loss: 0.0248 - val_accuracy: 1.0000\n",
      "Epoch 8/30\n",
      "144/144 [==============================] - 2s 15ms/sample - loss: 0.0459 - accuracy: 0.9861 - val_loss: 0.0061 - val_accuracy: 1.0000\n",
      "Epoch 9/30\n",
      "144/144 [==============================] - 2s 14ms/sample - loss: 0.0326 - accuracy: 0.9931 - val_loss: 0.0057 - val_accuracy: 1.0000\n",
      "Epoch 10/30\n",
      "144/144 [==============================] - 2s 14ms/sample - loss: 0.0230 - accuracy: 0.9931 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
      "Epoch 11/30\n",
      "144/144 [==============================] - 2s 16ms/sample - loss: 0.0103 - accuracy: 1.0000 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
      "Epoch 12/30\n",
      "144/144 [==============================] - 2s 15ms/sample - loss: 0.0058 - accuracy: 1.0000 - val_loss: 8.4828e-04 - val_accuracy: 1.0000\n",
      "Epoch 13/30\n",
      "144/144 [==============================] - 2s 14ms/sample - loss: 0.0037 - accuracy: 1.0000 - val_loss: 5.7203e-04 - val_accuracy: 1.0000\n",
      "Epoch 14/30\n",
      "144/144 [==============================] - 2s 15ms/sample - loss: 0.0025 - accuracy: 1.0000 - val_loss: 4.1795e-04 - val_accuracy: 1.0000\n",
      "Epoch 15/30\n",
      "144/144 [==============================] - 2s 14ms/sample - loss: 0.0017 - accuracy: 1.0000 - val_loss: 3.5078e-04 - val_accuracy: 1.0000\n",
      "Epoch 16/30\n",
      "144/144 [==============================] - 2s 16ms/sample - loss: 0.0014 - accuracy: 1.0000 - val_loss: 2.9565e-04 - val_accuracy: 1.0000\n",
      "Epoch 17/30\n",
      "144/144 [==============================] - 2s 16ms/sample - loss: 0.0011 - accuracy: 1.0000 - val_loss: 2.7666e-04 - val_accuracy: 1.0000\n",
      "Epoch 18/30\n",
      "144/144 [==============================] - 2s 15ms/sample - loss: 9.7321e-04 - accuracy: 1.0000 - val_loss: 2.2228e-04 - val_accuracy: 1.0000\n",
      "Epoch 19/30\n",
      "144/144 [==============================] - 2s 15ms/sample - loss: 8.4304e-04 - accuracy: 1.0000 - val_loss: 1.9860e-04 - val_accuracy: 1.0000\n",
      "Epoch 20/30\n",
      "144/144 [==============================] - 2s 15ms/sample - loss: 6.9953e-04 - accuracy: 1.0000 - val_loss: 1.7914e-04 - val_accuracy: 1.0000\n",
      "Epoch 21/30\n",
      "144/144 [==============================] - 2s 16ms/sample - loss: 6.2386e-04 - accuracy: 1.0000 - val_loss: 1.5895e-04 - val_accuracy: 1.0000\n",
      "Epoch 22/30\n",
      "144/144 [==============================] - 2s 15ms/sample - loss: 5.8827e-04 - accuracy: 1.0000 - val_loss: 1.3826e-04 - val_accuracy: 1.0000\n",
      "Epoch 23/30\n",
      "144/144 [==============================] - 2s 15ms/sample - loss: 4.9434e-04 - accuracy: 1.0000 - val_loss: 1.3285e-04 - val_accuracy: 1.0000\n",
      "Epoch 24/30\n",
      "144/144 [==============================] - 2s 16ms/sample - loss: 4.6183e-04 - accuracy: 1.0000 - val_loss: 1.1786e-04 - val_accuracy: 1.0000\n",
      "Epoch 25/30\n",
      "144/144 [==============================] - 2s 15ms/sample - loss: 4.1602e-04 - accuracy: 1.0000 - val_loss: 1.1001e-04 - val_accuracy: 1.0000\n",
      "Epoch 26/30\n",
      "144/144 [==============================] - 2s 16ms/sample - loss: 3.7038e-04 - accuracy: 1.0000 - val_loss: 1.0738e-04 - val_accuracy: 1.0000\n",
      "Epoch 27/30\n",
      "144/144 [==============================] - 2s 16ms/sample - loss: 3.3490e-04 - accuracy: 1.0000 - val_loss: 9.6675e-05 - val_accuracy: 1.0000\n",
      "Epoch 28/30\n",
      "144/144 [==============================] - 2s 15ms/sample - loss: 3.0927e-04 - accuracy: 1.0000 - val_loss: 9.0097e-05 - val_accuracy: 1.0000\n",
      "Epoch 29/30\n",
      "144/144 [==============================] - 2s 15ms/sample - loss: 2.8928e-04 - accuracy: 1.0000 - val_loss: 8.5285e-05 - val_accuracy: 1.0000\n",
      "Epoch 30/30\n",
      "144/144 [==============================] - 2s 15ms/sample - loss: 2.6269e-04 - accuracy: 1.0000 - val_loss: 7.9757e-05 - val_accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# Training the model\n",
    "import time\n",
    "i = 0\n",
    "for model in models:\n",
    "#     name = \"logs/OpenClosedEye_with_Batchsize\" + str(i)\n",
    "#     tensorboard = TensorBoard(log_dir=name)\n",
    "    model.fit(train_images, train_labels, epochs=30, batch_size=16 ,validation_data=(X_valid, y_valid), callbacks=[es])\n",
    "    i = i+1\n",
    "#    model.save_weights(\"model_currentbest\"+\"tf\")\n",
    "    model.save(\"model_currentbest\"+\".h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-5335fc81ff67f6aa\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-5335fc81ff67f6aa\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          url.port = 6006;\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Unable to open file (unable to open file: name = 'model0.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-93-09f9ceecf261>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# eval_images = [preprocess_image(load_image(file)) for file in uploads].keys()]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0meval_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLayersCollection\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0meval_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"model0.h5\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0meval_predictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meval_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/spyder/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mload_weights\u001b[0;34m(self, filepath, by_name, skip_mismatch)\u001b[0m\n\u001b[1;32m    232\u001b[0m         raise ValueError('Load weights is not yet supported with TPUStrategy '\n\u001b[1;32m    233\u001b[0m                          'with steps_per_run greater than 1.')\n\u001b[0;32m--> 234\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mby_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskip_mismatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mtrackable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_automatic_dependency_tracking\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/spyder/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/network.py\u001b[0m in \u001b[0;36mload_weights\u001b[0;34m(self, filepath, by_name, skip_mismatch)\u001b[0m\n\u001b[1;32m   1213\u001b[0m           'first, then load the weights.')\n\u001b[1;32m   1214\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_assert_weights_created\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1215\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1216\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'layer_names'\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattrs\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m'model_weights'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1217\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model_weights'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/spyder/lib/python3.7/site-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode, driver, libver, userblock_size, swmr, **kwds)\u001b[0m\n\u001b[1;32m    310\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mphil\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m                 \u001b[0mfapl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_fapl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdriver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlibver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 312\u001b[0;31m                 \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_fid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muserblock_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mswmr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mswmr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/spyder/lib/python3.7/site-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36mmake_fid\u001b[0;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mswmr\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m             \u001b[0mflags\u001b[0m \u001b[0;34m|=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_SWMR_READ\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'r+'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_RDWR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/h5f.pyx\u001b[0m in \u001b[0;36mh5py.h5f.open\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: Unable to open file (unable to open file: name = 'model0.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import cv2\n",
    "\n",
    "test_file = \"closed_eye_75.jpg\"\n",
    "uploads = cv2.imread(\"test/\" + test_file)\n",
    "\n",
    "\"\"\" For Multiple Images...\n",
    "import glob\n",
    "import cv2\n",
    "images = [cv2.imread(file) for file in glob.glob(\"path/to/files/*.png\")]\n",
    "\"\"\"\n",
    "\n",
    "eval_images = [preprocess_image(uploads)] # must be an array because of the for-loop below\n",
    "# eval_images = [preprocess_image(load_image(file)) for file in uploads].keys()]\n",
    "eval_model = tf.keras.Sequential(LayersCollection[0])\n",
    "eval_model.load_weights(\"model0.h5\")\n",
    "eval_predictions = eval_model.predict(np.expand_dims(eval_images, axis = -1))\n",
    "\n",
    "cols = 4\n",
    "rows = np.ceil(len(eval_images)/cols)\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(cols*4, rows*4)\n",
    "for i in range(len(eval_images)):\n",
    "    plt.subplot(rows, cols, i+1)\n",
    "    plt.imshow(eval_images[i], cmap=\"gray\")\n",
    "    plt.title(\"Open\" if np.argmax(eval_predictions[i])==1 else \"Closed\")\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'models' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-faa34c4b5a7a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     28\u001b[0m                                 \u001b[0mtemp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mpreprocess_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m                                 \u001b[0mbegin_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m                                 \u001b[0meval_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m                                 \u001b[0meval_predictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m                                 \u001b[0mend_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'models' is not defined"
     ]
    }
   ],
   "source": [
    "test_path = \"gabor/gabor50-0_test/\"\n",
    "test_files = os.listdir(test_path)\n",
    "test_images = [load_image(test_path + file) for file in test_files]\n",
    "test_labels = [extract_label(file) for file in test_files]\n",
    "\n",
    "# eval_model = tf.keras.Sequential(layers)\n",
    "# eval_model.load_weights(\"model.h5\")\n",
    "\n",
    "import time\n",
    "\n",
    "above = []\n",
    "lantancys = []\n",
    "accur = []\n",
    "\n",
    "j = 0\n",
    "\n",
    "for f in range(len(Optimizers)):\n",
    "    for a in range(len(Batch_Sizes)):\n",
    "        for k in range(len(Epoch_Sizes)):\n",
    "            for x in range(len(Activations)):\n",
    "                for Num_Hidden in NumberOfHiddenLayer:\n",
    "                    for ks in Kernel_Size:\n",
    "                        for pool in PoolSize:\n",
    "                            right = 0\n",
    "                            total = 0\n",
    "                            for i in range(len(test_images)):\n",
    "                                temp = test_images[i]\n",
    "                                temp = [preprocess_image(temp)]\n",
    "                                begin_time = int(round(time.time() * 1000))\n",
    "                                eval_model = models[x]\n",
    "                                eval_predictions = eval_model.predict(np.expand_dims(temp , axis= -1))\n",
    "                                end_time = int(round(time.time() * 1000))\n",
    "                                if (test_labels[i] == 1 and np.argmax(eval_predictions[0])==1) or (test_labels[i] == 0 and np.argmax(eval_predictions[0])!=1):\n",
    "                                    right+=1\n",
    "                                total+= end_time-begin_time\n",
    "\n",
    "                            print(\"accuracy for \",j,\" is :\",right/64*100 , \"%\")\n",
    "                            print(\"time spent for \" ,j, \" is : \" , total , \"ms\")\n",
    "                            j = j +1\n",
    "                            above.append(x)\n",
    "                            lantancys.append(total)\n",
    "                            accur.append(right/64*100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test_path = \"gabor/gabor50-45_test/\"\n",
    "test_files = os.listdir(test_path)\n",
    "test_images = [load_image(test_path + file) for file in test_files]\n",
    "test_labels = [extract_label(file) for file in test_files]\n",
    "\n",
    "# eval_model = tf.keras.Sequential(layers)\n",
    "# eval_model.load_weights(\"model.h5\")\n",
    "\n",
    "import time\n",
    "\n",
    "above = []\n",
    "lantancys = []\n",
    "accur = []\n",
    "\n",
    "j = 0\n",
    "right = 0\n",
    "total = 0\n",
    "for i in range(len(test_images)):\n",
    "    temp = test_images[i]\n",
    "    temp = [preprocess_image(temp)]\n",
    "    begin_time = int(round(time.time() * 1000))\n",
    "    eval_model = model\n",
    "    eval_predictions = eval_model.predict(np.expand_dims(temp , axis= -1))\n",
    "    end_time = int(round(time.time() * 1000))\n",
    "    if (test_labels[i] == 1 and np.argmax(eval_predictions[0])==1) or (test_labels[i] == 0 and np.argmax(eval_predictions[0])!=1):\n",
    "        right+=1\n",
    "    total+= end_time-begin_time\n",
    "\n",
    "print(\"accuracy for \",j,\" is :\",right/64*100 , \"%\")\n",
    "print(\"time spent for \" ,j, \" is : \" , total , \"ms\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test_path = \"gabor/gabor100-45_test/\"\n",
    "test_files = os.listdir(test_path)\n",
    "test_images = [load_image(test_path + file) for file in test_files]\n",
    "test_labels = [extract_label(file) for file in test_files]\n",
    "\n",
    "# eval_model = tf.keras.Sequential(layers)\n",
    "# eval_model.load_weights(\"model.h5\")\n",
    "\n",
    "import time\n",
    "\n",
    "above = []\n",
    "lantancys = []\n",
    "accur = []\n",
    "\n",
    "j = 0\n",
    "right = 0\n",
    "total = 0\n",
    "for i in range(len(test_images)):\n",
    "    temp = test_images[i]\n",
    "    temp = [preprocess_image(temp)]\n",
    "    begin_time = int(round(time.time() * 1000))\n",
    "    eval_model = model\n",
    "    eval_predictions = eval_model.predict(np.expand_dims(temp , axis= -1))\n",
    "    end_time = int(round(time.time() * 1000))\n",
    "    if (test_labels[i] == 1 and np.argmax(eval_predictions[0])==1) or (test_labels[i] == 0 and np.argmax(eval_predictions[0])!=1):\n",
    "        right+=1\n",
    "    total+= end_time-begin_time\n",
    "\n",
    "print(\"accuracy for \",j,\" is :\",right/64*100 , \"%\")\n",
    "print(\"time spent for \" ,j, \" is : \" , total , \"ms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy for Learning rate  0.001  is : 93.75 %\n",
      "time spent for  0.001  is :  1701 ms\n"
     ]
    }
   ],
   "source": [
    "test_path = \"ftest2/\"\n",
    "test_files = os.listdir(test_path)\n",
    "test_images = [load_image(test_path + file) for file in test_files]\n",
    "test_labels = [extract_label(file) for file in test_files]\n",
    "\n",
    "# eval_model = tf.keras.Sequential(layers)\n",
    "# eval_model.load_weights(\"model.h5\")\n",
    "\n",
    "import time\n",
    "\n",
    "above = []\n",
    "lantancys = []\n",
    "accur = []\n",
    "\n",
    "j = 0\n",
    "right = 0\n",
    "total = 0\n",
    "k = 0\n",
    "for model in models:\n",
    "    for i in range(len(test_images)):\n",
    "        temp = test_images[i]\n",
    "        temp = [preprocess_image(temp)]\n",
    "        begin_time = int(round(time.time() * 1000))\n",
    "        eval_model = model\n",
    "        eval_predictions = eval_model.predict(np.expand_dims(temp , axis= -1))\n",
    "        end_time = int(round(time.time() * 1000))\n",
    "        if (test_labels[i] == 1 and np.argmax(eval_predictions[0])==1) or (test_labels[i] == 0 and np.argmax(eval_predictions[0])!=1):\n",
    "            right+=1\n",
    "        total+= end_time-begin_time\n",
    "\n",
    "    print(\"accuracy for Learning rate \",Learning_Rate[k] ,\" is :\",right/64*100 , \"%\")\n",
    "    print(\"time spent for \",Learning_Rate[k], \" is : \" , total , \"ms\")\n",
    "    right = 0\n",
    "    total = 0\n",
    "    k = k +1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizer_coll = []\n",
    "# activition_coll = []\n",
    "# Batch_size_coll = []\n",
    "# Epoch_size_coll = []\n",
    "# num_hidden_coll = []\n",
    "# Filetersize_coll = []\n",
    "# pool_coll = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 6, 8, 9, 15, 19, 20, 24, 26, 27, 30, 31, 33, 34, 37, 39, 40, 41, 42, 43, 45, 48, 49]\n"
     ]
    }
   ],
   "source": [
    "print(above)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optmizer: adam ,Activition function: relu ,Num of hiddenlayer: 2 ,Kernel size:  3  with lantancys : 28.609375 ms   ,accurancy:  98.4375 %\n",
      "optmizer: adam ,Activition function: relu ,Num of hiddenlayer: 3 ,Kernel size:  3  with lantancys : 28.453125 ms   ,accurancy:  98.4375 %\n",
      "optmizer: adam ,Activition function: relu ,Num of hiddenlayer: 3 ,Kernel size:  5  with lantancys : 31.6875 ms   ,accurancy:  100.0 %\n",
      "optmizer: adam ,Activition function: elu ,Num of hiddenlayer: 1 ,Kernel size:  3  with lantancys : 28.53125 ms   ,accurancy:  98.4375 %\n",
      "optmizer: adam ,Activition function: elu ,Num of hiddenlayer: 3 ,Kernel size:  3  with lantancys : 29.03125 ms   ,accurancy:  100.0 %\n",
      "optmizer: adagrad ,Activition function: relu ,Num of hiddenlayer: 1 ,Kernel size:  4  with lantancys : 29.515625 ms   ,accurancy:  98.4375 %\n",
      "optmizer: adagrad ,Activition function: relu ,Num of hiddenlayer: 1 ,Kernel size:  5  with lantancys : 31.78125 ms   ,accurancy:  98.4375 %\n",
      "optmizer: adagrad ,Activition function: relu ,Num of hiddenlayer: 3 ,Kernel size:  3  with lantancys : 28.78125 ms   ,accurancy:  98.4375 %\n",
      "optmizer: adagrad ,Activition function: relu ,Num of hiddenlayer: 3 ,Kernel size:  5  with lantancys : 37.328125 ms   ,accurancy:  98.4375 %\n",
      "optmizer: adagrad ,Activition function: elu ,Num of hiddenlayer: 1 ,Kernel size:  3  with lantancys : 28.96875 ms   ,accurancy:  100.0 %\n",
      "optmizer: adagrad ,Activition function: elu ,Num of hiddenlayer: 2 ,Kernel size:  3  with lantancys : 28.71875 ms   ,accurancy:  100.0 %\n",
      "optmizer: adagrad ,Activition function: elu ,Num of hiddenlayer: 2 ,Kernel size:  4  with lantancys : 30.328125 ms   ,accurancy:  98.4375 %\n",
      "optmizer: adagrad ,Activition function: elu ,Num of hiddenlayer: 3 ,Kernel size:  3  with lantancys : 28.5625 ms   ,accurancy:  100.0 %\n",
      "optmizer: adagrad ,Activition function: elu ,Num of hiddenlayer: 3 ,Kernel size:  4  with lantancys : 29.90625 ms   ,accurancy:  98.4375 %\n",
      "optmizer: nadam ,Activition function: relu ,Num of hiddenlayer: 1 ,Kernel size:  4  with lantancys : 29.234375 ms   ,accurancy:  98.4375 %\n",
      "optmizer: nadam ,Activition function: relu ,Num of hiddenlayer: 2 ,Kernel size:  3  with lantancys : 28.0625 ms   ,accurancy:  100.0 %\n",
      "optmizer: nadam ,Activition function: relu ,Num of hiddenlayer: 2 ,Kernel size:  4  with lantancys : 29.796875 ms   ,accurancy:  100.0 %\n",
      "optmizer: nadam ,Activition function: relu ,Num of hiddenlayer: 2 ,Kernel size:  5  with lantancys : 31.421875 ms   ,accurancy:  98.4375 %\n",
      "optmizer: nadam ,Activition function: relu ,Num of hiddenlayer: 3 ,Kernel size:  3  with lantancys : 28.203125 ms   ,accurancy:  98.4375 %\n",
      "optmizer: nadam ,Activition function: relu ,Num of hiddenlayer: 3 ,Kernel size:  4  with lantancys : 30.109375 ms   ,accurancy:  98.4375 %\n",
      "optmizer: nadam ,Activition function: elu ,Num of hiddenlayer: 1 ,Kernel size:  3  with lantancys : 28.515625 ms   ,accurancy:  98.4375 %\n",
      "optmizer: nadam ,Activition function: elu ,Num of hiddenlayer: 2 ,Kernel size:  3  with lantancys : 29.28125 ms   ,accurancy:  98.4375 %\n",
      "optmizer: nadam ,Activition function: elu ,Num of hiddenlayer: 2 ,Kernel size:  4  with lantancys : 29.734375 ms   ,accurancy:  98.4375 %\n"
     ]
    }
   ],
   "source": [
    "for i , j , k in zip(above, lantancys , accur):\n",
    "    print(\"optmizer:\" , Optimizer_coll[i] , \",Activition function:\", activition_coll[i] , \",Num of hiddenlayer:\" , num_hidden_coll[i] ,\",Kernel size: \", K_size[i] , \" with lantancys :\" , j/64 , \"ms\", \"  ,accurancy: \" , k , \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "img_arr = np.array(preprocess_image(uploads))\n",
    "print(len(img_arr.flatten()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
